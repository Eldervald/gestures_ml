{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "# from torchvision.io import read_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', message=r'.*ReplayMode.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FRAMES_PER_VIDEO = 16\n",
    "RESIZE_SHAPE = 256\n",
    "SEED = 54\n",
    "\n",
    "def read_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(frame)\n",
    "    \n",
    "#     if len(frames) > 0:\n",
    "#         frames = frames[len(frames) // 2-2:len(frames) // 2+3]\n",
    "    \n",
    "    return np.array(frames)\n",
    "\n",
    "transform = A.Compose([\n",
    "     A.LongestMaxSize(max_size=RESIZE_SHAPE),\n",
    "])\n",
    "\n",
    "def video2rgb(filename, out_dir):\n",
    "    file_template = 'img_{0:04d}.jpg'\n",
    "    reader = cv2.VideoCapture(filename)\n",
    "    success, frame, = reader.read()  # read first frame\n",
    "\n",
    "    count = 0\n",
    "    while success:\n",
    "        # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = cv2.resize(frame, (RESIZE_SHAPE, RESIZE_SHAPE))\n",
    "        frame = transform(image=frame)['image']\n",
    "        out_filepath = os.path.join(out_dir, file_template.format(count))\n",
    "        cv2.imwrite(out_filepath, frame)\n",
    "        success, frame = reader.read()\n",
    "        count += 1\n",
    "    if count == 0:\n",
    "        os.rmdir(out_dir)\n",
    "        \n",
    "def uniform_temporal_subsample(data, n_samples=FRAMES_PER_VIDEO):\n",
    "    n_frames = len(data)\n",
    "    indices = np.round(np.linspace(0, n_frames - 1, n_samples)).astype(np.int32)\n",
    "    data = data[indices]\n",
    "    return data\n",
    "\n",
    "def apply(video):\n",
    "    video = uniform_temporal_subsample(video)\n",
    "    res = []\n",
    "    for frame in video:\n",
    "        res.append(transform(image=frame)['image'])\n",
    "    return np.array(res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, Process, Manager\n",
    "\n",
    "class AutslDataset():\n",
    "    def __init__(self, ds_type, dir_path='data/autsl', csv_postfix_file_name=\"_labels.csv\"):\n",
    "        self.dir_path = dir_path\n",
    "        self.ds_type = ds_type\n",
    "\n",
    "        self.df = pd.read_csv(os.path.join(dir_path, ds_type+csv_postfix_file_name), header=None)\n",
    "        self.df.columns = ['filename', 'cls']\n",
    "        self.num_classes = int(self.df['cls'].max() + 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        sample = self.df.iloc[ind]\n",
    "        video_path = os.path.join(self.dir_path, self.ds_type, sample[\"filename\"] + '_color.mp4')\n",
    "\n",
    "        video = read_video(video_path)\n",
    "        if len(video.shape) != 4:\n",
    "            print(video_path)\n",
    "            ind = np.random.randint(len(self))\n",
    "            return self[ind]\n",
    "\n",
    "        return video, sample['cls']\n",
    "    \n",
    "    def handle_video(self, idx, out_dir_path='data/autsl_frames'):\n",
    "        try:\n",
    "            sample = self.df.iloc[idx]\n",
    "            cls = sample['cls']\n",
    "            video_path = os.path.join(self.dir_path, self.ds_type, sample[\"filename\"] + '_color.mp4')\n",
    "            \n",
    "            out_video_folder = os.path.join(out_dir_path, self.ds_type, str(cls), str(idx))\n",
    "            # print(out_video_folder)\n",
    "            Path(out_video_folder).mkdir(parents=True, exist_ok=True)\n",
    "            video2rgb(video_path, out_video_folder)\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "    \n",
    "    def create_np_ds(self, dir_path='data/autsl_np16'):\n",
    "        ds_path = os.path.join(dir_path, self.ds_type)\n",
    "        Path(ds_path).mkdir(parents=True, exist_ok=True)\n",
    "        for idx in tqdm(range(len(self))):\n",
    "            video, cls = self[idx]\n",
    "            cls_dir_path = os.path.join(ds_path, str(cls))\n",
    "            Path(cls_dir_path).mkdir(parents=True, exist_ok=True)\n",
    "            np.save(os.path.join(cls_dir_path, str(idx)), apply(video))\n",
    "    \n",
    "    def create_frames_ds(self, dir_path='data/autsl_frames'):\n",
    "        pool = Pool(8)\n",
    "        pool.map(self.handle_video, tqdm(list(range(len(self)))))\n",
    "\n",
    "ds = AutslDataset('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 512, 512, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[97][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5270d9a6a3f64959ac212d8418ab2b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3742 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5641ce834700] moov atom not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/autsl/test/signer6_sample185_color.mp4\n"
     ]
    }
   ],
   "source": [
    "ds.create_np_ds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_annotations_file(dir):\n",
    "    with open(os.path.join(dir, 'annotations.txt'), 'w') as f:\n",
    "        for cls in sorted(os.listdir(dir)):\n",
    "            if cls == 'annotations.txt' or cls.startswith('.'):\n",
    "                continue\n",
    "            for vid_folder in sorted(os.listdir(os.path.join(dir, cls))):\n",
    "                vid_folder_path = os.path.join(dir, cls, vid_folder)\n",
    "                f.write(f'{os.path.join(cls, vid_folder)} 0 {len(os.listdir(vid_folder_path)) - 1} {cls}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_annotations_file('data/autsl_frames/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
